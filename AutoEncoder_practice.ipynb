{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d426e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1f90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies= pd.read_csv('ml-1m/movies.dat',sep = '::', header = None, engine = 'python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1657240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1                            2\n",
       "0  1  Toy Story (1995)  Animation|Children's|Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[movies[1] == 'Toy Story (1995)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cea82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "users= pd.read_csv('ml-1m/users.dat',sep = '::', header = None, engine = 'python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06551bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1   2   3      4\n",
       "0        1  F   1  10  48067\n",
       "1        2  M  56  16  70072\n",
       "2        3  M  25  15  55117\n",
       "3        4  M  45   7  02460\n",
       "4        5  M  25  20  55455\n",
       "...    ... ..  ..  ..    ...\n",
       "6035  6036  F  25  15  32603\n",
       "6036  6037  F  45   1  76006\n",
       "6037  6038  F  56   1  14706\n",
       "6038  6039  F  45   0  01060\n",
       "6039  6040  M  25   6  11106\n",
       "\n",
       "[6040 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc868c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings= pd.read_csv('ml-1m/ratings.dat',sep = '::', header = None, engine = 'python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f527cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1  2          3\n",
       "0           1  1193  5  978300760\n",
       "1           1   661  3  978302109\n",
       "2           1   914  3  978301968\n",
       "3           1  3408  4  978300275\n",
       "4           1  2355  5  978824291\n",
       "...       ...   ... ..        ...\n",
       "1000204  6040  1091  1  956716541\n",
       "1000205  6040  1094  5  956704887\n",
       "1000206  6040   562  5  956704746\n",
       "1000207  6040  1096  4  956715648\n",
       "1000208  6040  1097  4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c874309",
   "metadata": {},
   "source": [
    "column 0 is the user id <br>\n",
    "column 1 is the movie id <br>\n",
    "column 2 is the rating given by the user <br>\n",
    "column 3 is the time stamp <br>\n",
    "Note: For the user and movie details we can refer their data set loaded above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d895d3",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce1c328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b91fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>5</th>\n",
       "      <th>874965758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>875071561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>943</td>\n",
       "      <td>1067</td>\n",
       "      <td>2</td>\n",
       "      <td>875501756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "      <td>888640275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3</td>\n",
       "      <td>888692465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79999 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1   1.1  5  874965758\n",
       "0        1     2  3  876893171\n",
       "1        1     3  4  878542960\n",
       "2        1     4  3  876893119\n",
       "3        1     5  3  889751712\n",
       "4        1     7  4  875071561\n",
       "...    ...   ... ..        ...\n",
       "79994  943  1067  2  875501756\n",
       "79995  943  1074  4  888640250\n",
       "79996  943  1188  3  888640250\n",
       "79997  943  1228  3  888640275\n",
       "79998  943  1330  3  888692465\n",
       "\n",
       "[79999 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c5a84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set= np.array(training_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2844346e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ...,\n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb3c42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40eba497",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set= np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0e429",
   "metadata": {},
   "source": [
    "#### Getting the number of movies and number of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58591208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_users=  int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
    "nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a06e8639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_movies=  int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
    "nb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a87de",
   "metadata": {},
   "source": [
    "#### Function for converting a matrix of ratings as per user. rows has user and columns has movie wise ratings\n",
    "$$\\begin{bmatrix} 1 & 2 & 1 & ....\\\\ 3 & 0 & 1 & ....\\\\ 0 & 2 & 4 & .... \\\\ . \\\\ .\\end{bmatrix}$$ <br>\n",
    "where 0 rating means user did not rate the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be44d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    new_data = []\n",
    "    for user in range(1,nb_users+1):\n",
    "        id_movies= data[:,1][data[:,0]==user]\n",
    "        id_rating = data[:,2][data[:,0]==user]\n",
    "        rating= np.zeros(nb_movies)\n",
    "        rating[id_movies-1] = id_rating\n",
    "        new_data.append(list(rating))\n",
    "    return new_data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "775b70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set= convert(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d705afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set= convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "601f52b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set),len(training_set[0]) # dimenssion of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b1256",
   "metadata": {},
   "source": [
    "### Converting data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9796b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a9f23",
   "metadata": {},
   "source": [
    "### Autoencoder architecture \n",
    "#### Stacked auto encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f2657ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(nb_movies, 20) # out feature =20 is just an experimental value. We could tune it for best\n",
    "        self.fc2 = nn.Linear(20, 15) # 2nd hidden layer\n",
    "        self.fc3 = nn.Linear(15, 20) # 3rd hidden layer (Decoding or decompression process)\n",
    "        self.fc4 = nn.Linear(20, nb_movies) # 2nd hidden layer\n",
    "        self.activation = nn.Hardtanh()\n",
    "        self.activation1 = nn.Softmax()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x)) # x in fc1(x) is the first input vector applied to the network\n",
    "        x = self.activation(self.fc2(x)) # x in fc2(x) is the outpout of first hidden layer\n",
    "        x= self.activation1(self.fc3(x))\n",
    "        x = self.fc4(x) # now x will be the output of the Auto encoder\n",
    "        return x\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b61b32",
   "metadata": {},
   "source": [
    "### Training SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7a078ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katiy\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1   loss: tensor(3.2419)\n",
      "epoch: 2   loss: tensor(2.4788)\n",
      "epoch: 3   loss: tensor(2.0611)\n",
      "epoch: 4   loss: tensor(1.8061)\n",
      "epoch: 5   loss: tensor(1.6391)\n",
      "epoch: 6   loss: tensor(1.5222)\n",
      "epoch: 7   loss: tensor(1.4376)\n",
      "epoch: 8   loss: tensor(1.3731)\n",
      "epoch: 9   loss: tensor(1.3236)\n",
      "epoch: 10   loss: tensor(1.2836)\n",
      "epoch: 11   loss: tensor(1.2517)\n",
      "epoch: 12   loss: tensor(1.2248)\n",
      "epoch: 13   loss: tensor(1.2030)\n",
      "epoch: 14   loss: tensor(1.1839)\n",
      "epoch: 15   loss: tensor(1.1681)\n",
      "epoch: 16   loss: tensor(1.1540)\n",
      "epoch: 17   loss: tensor(1.1422)\n",
      "epoch: 18   loss: tensor(1.1314)\n",
      "epoch: 19   loss: tensor(1.1224)\n",
      "epoch: 20   loss: tensor(1.1139)\n",
      "epoch: 21   loss: tensor(1.1068)\n",
      "epoch: 22   loss: tensor(1.0998)\n",
      "epoch: 23   loss: tensor(1.0942)\n",
      "epoch: 24   loss: tensor(1.0885)\n",
      "epoch: 25   loss: tensor(1.0839)\n",
      "epoch: 26   loss: tensor(1.0792)\n",
      "epoch: 27   loss: tensor(1.0753)\n",
      "epoch: 28   loss: tensor(1.0713)\n",
      "epoch: 29   loss: tensor(1.0681)\n",
      "epoch: 30   loss: tensor(1.0646)\n",
      "epoch: 31   loss: tensor(1.0619)\n",
      "epoch: 32   loss: tensor(1.0589)\n",
      "epoch: 33   loss: tensor(1.0566)\n",
      "epoch: 34   loss: tensor(1.0540)\n",
      "epoch: 35   loss: tensor(1.0520)\n",
      "epoch: 36   loss: tensor(1.0497)\n",
      "epoch: 37   loss: tensor(1.0479)\n",
      "epoch: 38   loss: tensor(1.0458)\n",
      "epoch: 39   loss: tensor(1.0443)\n",
      "epoch: 40   loss: tensor(1.0425)\n",
      "epoch: 41   loss: tensor(1.0411)\n",
      "epoch: 42   loss: tensor(1.0394)\n",
      "epoch: 43   loss: tensor(1.0383)\n",
      "epoch: 44   loss: tensor(1.0367)\n",
      "epoch: 45   loss: tensor(1.0357)\n",
      "epoch: 46   loss: tensor(1.0343)\n",
      "epoch: 47   loss: tensor(1.0333)\n",
      "epoch: 48   loss: tensor(1.0321)\n",
      "epoch: 49   loss: tensor(1.0312)\n",
      "epoch: 50   loss: tensor(1.0300)\n",
      "epoch: 51   loss: tensor(1.0293)\n",
      "epoch: 52   loss: tensor(1.0282)\n",
      "epoch: 53   loss: tensor(1.0275)\n",
      "epoch: 54   loss: tensor(1.0265)\n",
      "epoch: 55   loss: tensor(1.0259)\n",
      "epoch: 56   loss: tensor(1.0249)\n",
      "epoch: 57   loss: tensor(1.0244)\n",
      "epoch: 58   loss: tensor(1.0234)\n",
      "epoch: 59   loss: tensor(1.0230)\n",
      "epoch: 60   loss: tensor(1.0221)\n",
      "epoch: 61   loss: tensor(1.0217)\n",
      "epoch: 62   loss: tensor(1.0209)\n",
      "epoch: 63   loss: tensor(1.0205)\n",
      "epoch: 64   loss: tensor(1.0197)\n",
      "epoch: 65   loss: tensor(1.0193)\n",
      "epoch: 66   loss: tensor(1.0186)\n",
      "epoch: 67   loss: tensor(1.0183)\n",
      "epoch: 68   loss: tensor(1.0176)\n",
      "epoch: 69   loss: tensor(1.0173)\n",
      "epoch: 70   loss: tensor(1.0167)\n",
      "epoch: 71   loss: tensor(1.0164)\n",
      "epoch: 72   loss: tensor(1.0158)\n",
      "epoch: 73   loss: tensor(1.0155)\n",
      "epoch: 74   loss: tensor(1.0149)\n",
      "epoch: 75   loss: tensor(1.0147)\n",
      "epoch: 76   loss: tensor(1.0141)\n",
      "epoch: 77   loss: tensor(1.0139)\n",
      "epoch: 78   loss: tensor(1.0134)\n",
      "epoch: 79   loss: tensor(1.0132)\n",
      "epoch: 80   loss: tensor(1.0127)\n",
      "epoch: 81   loss: tensor(1.0125)\n",
      "epoch: 82   loss: tensor(1.0120)\n",
      "epoch: 83   loss: tensor(1.0119)\n",
      "epoch: 84   loss: tensor(1.0114)\n",
      "epoch: 85   loss: tensor(1.0112)\n",
      "epoch: 86   loss: tensor(1.0108)\n",
      "epoch: 87   loss: tensor(1.0107)\n",
      "epoch: 88   loss: tensor(1.0102)\n",
      "epoch: 89   loss: tensor(1.0101)\n",
      "epoch: 90   loss: tensor(1.0096)\n",
      "epoch: 91   loss: tensor(1.0095)\n",
      "epoch: 92   loss: tensor(1.0090)\n",
      "epoch: 93   loss: tensor(1.0089)\n",
      "epoch: 94   loss: tensor(1.0085)\n",
      "epoch: 95   loss: tensor(1.0083)\n",
      "epoch: 96   loss: tensor(1.0078)\n",
      "epoch: 97   loss: tensor(1.0077)\n",
      "epoch: 98   loss: tensor(1.0072)\n",
      "epoch: 99   loss: tensor(1.0070)\n",
      "epoch: 100   loss: tensor(1.0065)\n",
      "epoch: 101   loss: tensor(1.0060)\n",
      "epoch: 102   loss: tensor(1.0051)\n",
      "epoch: 103   loss: tensor(1.0044)\n",
      "epoch: 104   loss: tensor(1.0028)\n",
      "epoch: 105   loss: tensor(1.0022)\n",
      "epoch: 106   loss: tensor(0.9997)\n",
      "epoch: 107   loss: tensor(0.9983)\n",
      "epoch: 108   loss: tensor(0.9956)\n",
      "epoch: 109   loss: tensor(0.9955)\n",
      "epoch: 110   loss: tensor(0.9929)\n",
      "epoch: 111   loss: tensor(0.9918)\n",
      "epoch: 112   loss: tensor(0.9905)\n",
      "epoch: 113   loss: tensor(0.9888)\n",
      "epoch: 114   loss: tensor(0.9881)\n",
      "epoch: 115   loss: tensor(0.9863)\n",
      "epoch: 116   loss: tensor(0.9853)\n",
      "epoch: 117   loss: tensor(0.9853)\n",
      "epoch: 118   loss: tensor(0.9830)\n",
      "epoch: 119   loss: tensor(0.9837)\n",
      "epoch: 120   loss: tensor(0.9803)\n",
      "epoch: 121   loss: tensor(0.9786)\n",
      "epoch: 122   loss: tensor(0.9778)\n",
      "epoch: 123   loss: tensor(0.9783)\n",
      "epoch: 124   loss: tensor(0.9766)\n",
      "epoch: 125   loss: tensor(0.9779)\n",
      "epoch: 126   loss: tensor(0.9750)\n",
      "epoch: 127   loss: tensor(0.9775)\n",
      "epoch: 128   loss: tensor(0.9771)\n",
      "epoch: 129   loss: tensor(0.9840)\n",
      "epoch: 130   loss: tensor(0.9814)\n",
      "epoch: 131   loss: tensor(0.9800)\n",
      "epoch: 132   loss: tensor(0.9791)\n",
      "epoch: 133   loss: tensor(0.9756)\n",
      "epoch: 134   loss: tensor(0.9746)\n",
      "epoch: 135   loss: tensor(0.9735)\n",
      "epoch: 136   loss: tensor(0.9733)\n",
      "epoch: 137   loss: tensor(0.9752)\n",
      "epoch: 138   loss: tensor(0.9758)\n",
      "epoch: 139   loss: tensor(0.9756)\n",
      "epoch: 140   loss: tensor(0.9761)\n",
      "epoch: 141   loss: tensor(0.9729)\n",
      "epoch: 142   loss: tensor(0.9700)\n",
      "epoch: 143   loss: tensor(0.9686)\n",
      "epoch: 144   loss: tensor(0.9692)\n",
      "epoch: 145   loss: tensor(0.9661)\n",
      "epoch: 146   loss: tensor(0.9664)\n",
      "epoch: 147   loss: tensor(0.9669)\n",
      "epoch: 148   loss: tensor(0.9660)\n",
      "epoch: 149   loss: tensor(0.9650)\n",
      "epoch: 150   loss: tensor(0.9637)\n",
      "epoch: 151   loss: tensor(0.9642)\n",
      "epoch: 152   loss: tensor(0.9634)\n",
      "epoch: 153   loss: tensor(0.9653)\n",
      "epoch: 154   loss: tensor(0.9641)\n",
      "epoch: 155   loss: tensor(0.9660)\n",
      "epoch: 156   loss: tensor(0.9648)\n",
      "epoch: 157   loss: tensor(0.9652)\n",
      "epoch: 158   loss: tensor(0.9638)\n",
      "epoch: 159   loss: tensor(0.9623)\n",
      "epoch: 160   loss: tensor(0.9627)\n",
      "epoch: 161   loss: tensor(0.9631)\n",
      "epoch: 162   loss: tensor(0.9624)\n",
      "epoch: 163   loss: tensor(0.9610)\n",
      "epoch: 164   loss: tensor(0.9605)\n",
      "epoch: 165   loss: tensor(0.9598)\n",
      "epoch: 166   loss: tensor(0.9584)\n",
      "epoch: 167   loss: tensor(0.9594)\n",
      "epoch: 168   loss: tensor(0.9625)\n",
      "epoch: 169   loss: tensor(0.9614)\n",
      "epoch: 170   loss: tensor(0.9591)\n",
      "epoch: 171   loss: tensor(0.9585)\n",
      "epoch: 172   loss: tensor(0.9594)\n",
      "epoch: 173   loss: tensor(0.9620)\n",
      "epoch: 174   loss: tensor(0.9640)\n",
      "epoch: 175   loss: tensor(0.9608)\n",
      "epoch: 176   loss: tensor(0.9601)\n",
      "epoch: 177   loss: tensor(0.9600)\n",
      "epoch: 178   loss: tensor(0.9632)\n",
      "epoch: 179   loss: tensor(0.9630)\n",
      "epoch: 180   loss: tensor(0.9599)\n",
      "epoch: 181   loss: tensor(0.9614)\n",
      "epoch: 182   loss: tensor(0.9619)\n",
      "epoch: 183   loss: tensor(0.9600)\n",
      "epoch: 184   loss: tensor(0.9591)\n",
      "epoch: 185   loss: tensor(0.9596)\n",
      "epoch: 186   loss: tensor(0.9581)\n",
      "epoch: 187   loss: tensor(0.9575)\n",
      "epoch: 188   loss: tensor(0.9568)\n",
      "epoch: 189   loss: tensor(0.9565)\n",
      "epoch: 190   loss: tensor(0.9567)\n",
      "epoch: 191   loss: tensor(0.9570)\n",
      "epoch: 192   loss: tensor(0.9575)\n",
      "epoch: 193   loss: tensor(0.9571)\n",
      "epoch: 194   loss: tensor(0.9574)\n",
      "epoch: 195   loss: tensor(0.9571)\n",
      "epoch: 196   loss: tensor(0.9561)\n",
      "epoch: 197   loss: tensor(0.9554)\n",
      "epoch: 198   loss: tensor(0.9548)\n",
      "epoch: 199   loss: tensor(0.9547)\n",
      "epoch: 200   loss: tensor(0.9543)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200\n",
    "for epoch in range(1, nb_epoch+1):\n",
    "    train_loss = 0\n",
    "    s = 0.  # we will use it to exclude the users who havent rate any movie\n",
    "    for id_user in range(nb_users):\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0) # to add a new dimession as per teh reqirements of nn\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data>0) > 0:\n",
    "            output = sae(input)\n",
    "            target.required_grad = False\n",
    "            output[target==0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data>0) +1e-10) # 1e-10 to avoid devison by zero\n",
    "            loss.backward() # decide the dirction in which weights are updated\n",
    "            train_loss += np.sqrt(loss.data* mean_corrector)\n",
    "            s += 1.\n",
    "            optimizer.step()  # decides the amount by what weights must be updated\n",
    "    print('epoch: ' + str(epoch) + '   loss: '+ str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa967e",
   "metadata": {},
   "source": [
    "### Testing the AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bacfa8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4,5,0,0]\n",
    "x = torch.FloatTensor(x)\n",
    "input = Variable(x).unsqueeze(0)\n",
    "input.require_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "36ab1856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.9914)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\katiy\\anaconda3\\envs\\gpu_test\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_users in range(nb_users):\n",
    "    input = Variable(training_set[id_users]).unsqueeze(0) # here we taken training set because SAE will take the ratings \n",
    "    ## of the user who has given the rating to the movie he has watched. Based on that data we will prdict that what raing\n",
    "    ## user will give to those movies which were not watched by particular user.\n",
    "    target = Variable(test_set[id_users]).unsqueeze(0) # target contains actual ratings\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.require_grad = False\n",
    "        output[target ==0] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8eaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
